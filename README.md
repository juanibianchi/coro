# CORO - Multi-LLM Chat Comparison

**CORO** (meaning "Chorus") is a multi-LLM chat application for comparing responses from different AI models side-by-side.

## ğŸ¯ Overview

Compare responses from 5 different AI models simultaneously:
- **Gemini 2.5 Flash** (Google)
- **Llama 3.3 70B** (Groq)
- **Llama 3.1 8B** (Groq)
- **Llama 4 Maverick 17B MoE** (Groq)
- **DeepSeek V2.5** (DeepSeek)

## ğŸ—ï¸ Architecture

```
coro/
â”œâ”€â”€ backend/          # FastAPI backend (Phase 1 âœ…)
â””â”€â”€ ios/             # SwiftUI iOS app (Phase 2 - Coming soon!)
```

## âœ… Phase 1: Backend (COMPLETE)

Production-ready FastAPI backend with:
- âœ… **5 LLM integrations** (4 working, 1 needs funding)
- âœ… **Parallel execution** (responses in < 2 seconds)
- âœ… **48 tests** (100% pass rate)
- âœ… **Production logging** (structured, informative)
- âœ… **Robust error handling** (graceful degradation)
- âœ… **Auto-generated API docs** at `/docs`

### Quick Start - Backend

```bash
# Install dependencies
cd backend
pip install -r requirements.txt

# Configure API keys
cp .env.example .env
# Edit .env and add your API keys

# Run tests
python -m pytest tests/ -v

# Start server
cd ..
python -m uvicorn backend.main:app --host 0.0.0.0 --port 8000
```

**Server runs at:** `http://localhost:8000`
**API Docs:** `http://localhost:8000/docs`

### API Endpoints

- `GET /health` - Health check
- `GET /models` - List available models
- `POST /chat` - Multi-model parallel chat
- `POST /chat/{model_id}` - Single model chat

### Test Results

```bash
======================== 48 passed in 4.45s ========================

âœ… API Endpoints: 14/14 tests
âœ… Schema Validation: 11/11 tests
âœ… Error Handling: 13/13 tests
âœ… Parallel Execution: 10/10 tests
```

## ğŸš€ Deployment

The backend is ready to deploy to:
- **Railway** (recommended)
- **Render**
- Any platform supporting Python/FastAPI

See `backend/Procfile` for deployment configuration.

## ğŸ“š Documentation

- **[Backend README](backend/README.md)** - Detailed backend documentation
- **[Test Report](TEST_REPORT.md)** - Comprehensive test coverage report
- **[Production Ready](PRODUCTION_READY.md)** - Deployment checklist
- **[Fixed Status](FIXED_STATUS.md)** - Model fixes and updates

## ğŸ”‘ API Keys

You'll need API keys from:
1. **Google Gemini** - https://aistudio.google.com/
2. **Groq** - https://console.groq.com/
3. **DeepSeek** - https://platform.deepseek.com/ (optional)

All are free or very cheap (~$0.14/1M tokens for DeepSeek).

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **Pydantic** - Data validation
- **httpx** - Async HTTP client
- **pytest** - Testing framework
- **uvicorn** - ASGI server

### iOS App (Coming Soon!)
- **SwiftUI** - Modern declarative UI
- **Swift 5.9+** - Programming language
- **Async/Await** - Concurrency
- **URLSession** - Networking

## ğŸ“Š Performance

- **Parallel Execution:** All models queried simultaneously
- **Response Time:** < 2 seconds for all 4 models
- **Individual Models:** 200ms - 1000ms depending on model
- **Proven:** Verified in automated tests

## ğŸ§ª Development

### Run Tests
```bash
cd backend
python -m pytest tests/ -v
```

### Run with Auto-Reload
```bash
python -m uvicorn backend.main:app --reload
```

### Check Code Coverage
```bash
python -m pytest tests/ --cov=backend --cov-report=html
open htmlcov/index.html
```

## ğŸ”’ Security

- âœ… API keys in environment variables (not hardcoded)
- âœ… Input validation with Pydantic
- âœ… CORS configured for frontend
- âœ… Error messages don't expose internals
- âœ… `.env` file in `.gitignore`

## ğŸ“ˆ Roadmap

- âœ… **Phase 1:** FastAPI Backend (COMPLETE)
- ğŸš§ **Phase 2:** iOS SwiftUI App (In Progress)
- ğŸ“‹ **Phase 3:** Streaming responses
- ğŸ“‹ **Phase 4:** Conversation history
- ğŸ“‹ **Phase 5:** Analytics & insights

## ğŸ¤ Contributing

This is a personal project, but feedback and suggestions are welcome!

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

Built with:
- FastAPI by SebastiÃ¡n RamÃ­rez
- Groq for fast LLM inference
- Google Gemini API
- DeepSeek for cost-effective inference

---

**Status:** Phase 1 Complete âœ… | Production Ready ğŸš€ | 48/48 Tests Passing âœ…
